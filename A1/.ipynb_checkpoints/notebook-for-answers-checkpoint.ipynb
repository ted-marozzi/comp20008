{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import ....\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# VAT algorithm provided for your use\n",
    "def VAT(R):\n",
    "    \"\"\"\n",
    "\n",
    "    VAT algorithm adapted from matlab version:\n",
    "    http://www.ece.mtu.edu/~thavens/code/VAT.m\n",
    "\n",
    "    Args:\n",
    "        R (n*n double): Dissimilarity data input\n",
    "        R (n*D double): vector input (R is converted to sq. Euclidean distance)\n",
    "    Returns:\n",
    "        RV (n*n double): VAT-reordered dissimilarity data\n",
    "        C (n int): Connection indexes of MST in [0,n)\n",
    "        I (n int): Reordered indexes of R, the input data in [0,n)\n",
    "    \"\"\"\n",
    "        \n",
    "    R = np.array(R)\n",
    "    N, M = R.shape\n",
    "    if N != M:\n",
    "        R = squareform(pdist(R))\n",
    "        \n",
    "    J = list(range(0, N))\n",
    "    \n",
    "    y = np.max(R, axis=0)\n",
    "    i = np.argmax(R, axis=0)\n",
    "    j = np.argmax(y)\n",
    "    y = np.max(y)\n",
    "\n",
    "\n",
    "    I = i[j]\n",
    "    del J[I]\n",
    "\n",
    "    y = np.min(R[I,J], axis=0)\n",
    "    j = np.argmin(R[I,J], axis=0)\n",
    "    \n",
    "    I = [I, J[j]]\n",
    "    J = [e for e in J if e != J[j]]\n",
    "    \n",
    "    C = [1,1]\n",
    "    for r in range(2, N-1):   \n",
    "        y = np.min(R[I,:][:,J], axis=0)\n",
    "        i = np.argmin(R[I,:][:,J], axis=0)\n",
    "        j = np.argmin(y)        \n",
    "        y = np.min(y)      \n",
    "        I.extend([J[j]])\n",
    "        J = [e for e in J if e != J[j]]\n",
    "        C.extend([i[j]])\n",
    "    \n",
    "    y = np.min(R[I,:][:,J], axis=0)\n",
    "    i = np.argmin(R[I,:][:,J], axis=0)\n",
    "    \n",
    "    I.extend(J)\n",
    "    C.extend(i)\n",
    "    \n",
    "    RI = list(range(N))\n",
    "    for idx, val in enumerate(I):\n",
    "        RI[val] = idx\n",
    "\n",
    "    RV = R[I,:][:,I]\n",
    "    \n",
    "    return RV.tolist(), C, I\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "Q1.1\n",
      "Number of traffic survey entries: 60168\n",
      "Number of attributes: 28\n",
      "\n",
      "date                      object\n",
      "road_name                 object\n",
      "location                  object\n",
      "suburb                    object\n",
      "speed_limit                int64\n",
      "direction                 object\n",
      "time                      object\n",
      "vehicle_class_1          float64\n",
      "vehicle_class_2          float64\n",
      "vehicle_class_3          float64\n",
      "vehicle_class_4          float64\n",
      "vehicle_class_5          float64\n",
      "vehicle_class_6          float64\n",
      "vehicle_class_7          float64\n",
      "vehicle_class_8          float64\n",
      "vehicle_class_9          float64\n",
      "vehicle_class_10         float64\n",
      "vehicle_class_11         float64\n",
      "vehicle_class_12         float64\n",
      "vehicle_class_13         float64\n",
      "motorcycle               float64\n",
      "bike                     float64\n",
      "average_speed            float64\n",
      "85th_percentile_speed    float64\n",
      "maximum_speed             object\n",
      "road_segment               int64\n",
      "road_segment_1           float64\n",
      "road_segment_2           float64\n",
      "dtype: object\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "#  Begin answering questions.  Please start a new cell for each question.\n",
    "# First Load the data in...\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "# Question 1.1\n",
    "# Read in traffic data frame\n",
    "traffic = pd.read_csv(\"traffic.csv\")\n",
    "# Find the shape of the data frame\n",
    "row, col = traffic.shape\n",
    "\n",
    "# Print out results\n",
    "print(\"***\\nQ1.1\")\n",
    "print(\"Number of traffic survey entries: \" + str(row))\n",
    "print(\"Number of attributes: \" + str(col) + \"\\n\")\n",
    "# Data types\n",
    "print(traffic.dtypes)\n",
    "print(\"***\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "Q1.2\n",
      "Number of remaining traffic survey entries: 41510\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "# Question 1.2\n",
    "print(\"***\\nQ1.2\")\n",
    "\n",
    "# Remove null entries\n",
    "traffic = traffic[traffic.maximum_speed != \"-\"]\n",
    "traffic = traffic[traffic.maximum_speed.notnull()]\n",
    "row, col = traffic.shape\n",
    "\n",
    "# Ensure that entries have been successfully removed\n",
    "print(\"Number of remaining traffic survey entries: \" + str(row))\n",
    "print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "Q1.3\n",
      "Median value of vehicle_class_1: 28.0\n",
      "Highest value of maximum_speed: 159\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "# Question 1.3\n",
    "print(\"***\\nQ1.3\")\n",
    "\n",
    "# Covert strings to floats and find median and max values\n",
    "traffic[\"maximum_speed\"] = pd.to_numeric(traffic[\"maximum_speed\"])\n",
    "median_class_1 = traffic[\"vehicle_class_1\"].median()\n",
    "max_speed = traffic[\"maximum_speed\"].max()\n",
    "\n",
    "# Print results\n",
    "print(\"Median value of vehicle_class_1: \" + str(median_class_1))\n",
    "print(\"Highest value of maximum_speed: \" + str(max_speed))\n",
    "print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-a6b07d0b3a83>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-a6b07d0b3a83>\"\u001b[1;36m, line \u001b[1;32m31\u001b[0m\n\u001b[1;33m    print(traffic.head(3)\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Question 2.1\n",
    "print(\"***\\nQ2.1\")\n",
    "\n",
    "# Set new attribute with default value for safety\n",
    "traffic[\"street_type\"] = '-'\n",
    "\n",
    "# Open roads.json into dataframe\n",
    "roads_json = json.load(open('roads.json'))\n",
    "roads_json = roads_json['data']\n",
    "roads_df = pd.DataFrame.from_dict(roads_json)\n",
    "\n",
    "# Copy over road tyoe by comparing seg_id\n",
    "road_segment = 0\n",
    "for i, row in enumerate(traffic[\"road_segment\"]):\n",
    "    last_road_segment = road_segment\n",
    "    road_segment = traffic.iloc[i][25]\n",
    "    \n",
    "    # Improves computation time by checking if the road segemnt is the same as the last one\n",
    "    # hence doesnt need to be re- located in roads.json\n",
    "    if road_segment == last_road_segment:\n",
    "        traffic.iat[i,28] = street_type\n",
    "    else:\n",
    "        # Finds the road segment from traffic dataframe in roads_df and copys the road type to traffic\n",
    "        # datd frame.\n",
    "        index = roads_df[roads_df[9].astype(int) == int(road_segment)].index.values.astype(int)[0]\n",
    "        street_type = roads_df[14][index]\n",
    "        traffic.iat[i,28] = street_type\n",
    "\n",
    "# Print results\n",
    "print(\"The first three rows of traffic DataFrame with the attribute StrType are: \")\n",
    "print(traffic.head(3)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 2.2\n",
    "print(\"***\\nQ2.2\")\n",
    "print(\"The first three rows of traffic DataFrame with the new max_speed_over_limit attribute are: \")\n",
    "\n",
    "# Create new column based on maximum speeed over limit, it was decided to keep negative results\n",
    "# as the questin was abigous as to how we should handle this case.\n",
    "traffic[\"max_speed_over_limit\"] = traffic[\"maximum_speed\"]-traffic[\"speed_limit\"]\n",
    "\n",
    "#print first 3 rows\n",
    "print(traffic.head(3))\n",
    "print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 2.3\n",
    "print(\"***\\nQ2.3\")\n",
    "\n",
    "# Create the arterial data fram from the traffic data frame\n",
    "arterials = traffic.loc[traffic['street_type'] == \"Arterial\"]\n",
    "arterials = arterials.groupby(\"road_name\")\n",
    "max_speed_roads = arterials[\"max_speed_over_limit\"].max().sort_values(ascending=False)\n",
    "\n",
    "print(\"Three Arterial roads with the highest maximum max_speed_over_limit: \")\n",
    "print(max_speed_roads.head(3))\n",
    "print(\"***\")\n",
    "\n",
    "# Question 2.3 comment\n",
    "text_1 = \"\"\"Question 2.3 comment) This infomation could be useful to VicRoads to help them identify which roads that they control had the\n",
    "worst speeding offences commited on them and thus enable them to deploy saftey measures such as speed cameras\n",
    "and warning signs to reduce the likely hood of speeding and thus injury/death on them.\"\"\"\n",
    "\n",
    "print(text_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 3.1a\n",
    "traffic = traffic.replace(\"CARLTON\", \"Carlton\")\n",
    "\n",
    "# Create and label plot of average speed per suburb\n",
    "mean_speed = traffic.groupby(\"suburb\")[\"average_speed\"].mean()\n",
    "mean_speed_plt = mean_speed.plot.bar()\n",
    "mean_speed_plt.set_title(\"Average speed of vehicle per suburb\")\n",
    "mean_speed_plt.set(xlabel=\"Suburb\", ylabel=\"Average speed of vehicle (km/h)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Question 3.1b\n",
    "# Box plot short vehicles\n",
    "short_vehicles = traffic[\"vehicle_class_1\"]\n",
    "plt.figure(figsize=(25,25))\n",
    "plt.boxplot(short_vehicles)\n",
    "plt.title(\"Box plot of vehicle class 1 distrubution.\", fontsize = 30)\n",
    "plt.ylabel(\"Number of class one vehicles\", fontsize = 30)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "# Question 3.1 comment\n",
    "text_2 = \"\"\"Question 3.1 comment) We can observe that outer suburbs tend to have higher mean speeds perhaps due to lower levels of traffic.\n",
    "Furthermore the box plot of the number of short vehicles shows very interesting results. We can see that the data\n",
    "has a very high variance and is extremly positivly skewed, pushing large proprtions of the data outside the 4th\n",
    "quartile\"\"\"\n",
    "\n",
    "print(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 3.2a\n",
    "# Create a random sample with seed.\n",
    "special_traffic = pd.read_csv(\"special_traffic.csv\").sample(1000, random_state = 1354)\n",
    "special_traffic.head()\n",
    "special_traffic_2 = special_traffic.drop([\"idx\",\"StrType\"], axis=1)\n",
    "\n",
    "# Perform PCA for 2 components to reduce dimentionality\n",
    "sklearn_pca = sklearnPCA(n_components=2)\n",
    "special_traffic_sklearn = sklearn_pca.fit_transform(special_traffic_2)\n",
    "print(\"Variance explained by each PC\",sklearn_pca.explained_variance_ratio_) \n",
    " \n",
    "# Use contrasting colours\n",
    "palette = ['blue','green']\n",
    "colors=special_traffic.StrType.replace(to_replace=special_traffic.StrType.unique(),value=palette).tolist()\n",
    "\n",
    "# Plot the coloured scatter plot\n",
    "plt.scatter(special_traffic_sklearn[:,0],special_traffic_sklearn[:,1],s=60,c=colors)\n",
    "plt.xlabel('1st Principal Component (units)', fontsize=10)\n",
    "plt.ylabel('2nd Principal Component (units)', fontsize=10)\n",
    "plt.title(\"Principle component analysis of special traffic dataframe\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Question 3.2b comment\n",
    "text_3 = \"\"\"Question 3.2b comment) It appears that the first principle component is a linear combination of \n",
    "vehicle class attibutes judging by the scale and the second principle\n",
    "component appears to be related to speed of vehicle.\"\"\"\n",
    "\n",
    "print(text_3)\n",
    "\n",
    "# Question 3.2c\n",
    "\n",
    "# Vat heat map on unaltered dataframe.\n",
    "RV, C, I = VAT(special_traffic_2)\n",
    "x=sns.heatmap(RV,cmap='viridis',xticklabels=False,yticklabels=False)\n",
    "x.set_title(\"VAT heat map of special traffic dataframe\", fontsize=20)\n",
    "x.set(xlabel='Objects', ylabel='Objects')\n",
    "plt.show()\n",
    "\n",
    "# Vat heat map on PCA dataframe.\n",
    "RV, C, I = VAT(special_traffic_sklearn)\n",
    "x=sns.heatmap(RV,cmap='viridis',xticklabels=False,yticklabels=False)\n",
    "x.set(xlabel='Objects', ylabel='Objects')\n",
    "x.set_title(\"PCA and VAT heat map of special traffic dataframe\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# Question 3.2d comment\n",
    "text_4 = \"\"\"Question 3.2d comment) The two vat plots look similar, hence the principle componets represent the\n",
    "important parts of the data. Some small clusters have been lost as can be seen in the lower right\n",
    "corner of the VAT heat maps.\"\"\"\n",
    "\n",
    "print(text_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 3.3a\n",
    "# Normalising the special traffic dataframe\n",
    "special_traffic_2.head()\n",
    "cols = special_traffic_2.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(special_traffic_2)\n",
    "special_traffic_2_norm = pd.DataFrame(np_scaled, columns = cols)\n",
    "special_traffic_2_norm\n",
    "\n",
    "# Performing kmeans for 1 to 10 clusters\n",
    "sse = {}\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(special_traffic_2_norm)\n",
    "    # Which cluster each row belongs to.\n",
    "    special_traffic_2_norm[\"clusters\"] = kmeans.labels_\n",
    "    # Sum of square errors\n",
    "    sse[k] = kmeans.inertia_\n",
    "    \n",
    "# Plot results\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.title(\"The sum of square error per number of k means clusters\")\n",
    "\n",
    "# Question 3.3a comment\n",
    "text_4 = \"\"\"Question 3.3a comment) The elbow plot is hard to interpret as there is no clear elbow however it suggests\n",
    "about 4 to 5 clusters is appropriate, this aggrees with the VAT heatmap results on the two principle \n",
    "components which suggests about 4 clusters.\"\"\"\n",
    "print(text_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 3.3b\n",
    "# Performing kmeans on k=3\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, max_iter=1000).fit(special_traffic_2_norm)\n",
    "\n",
    "# Plotting a bar plot by assigning each row to a cluster and summing them up\n",
    "special_traffic_2_norm[\"clusters\"] = kmeans.labels_\n",
    "special_traffic_2_norm.head(10)\n",
    "clusters = special_traffic_2_norm[\"clusters\"].value_counts().sort_index()\n",
    "clusters_plt = clusters.plot.bar()\n",
    "clusters_plt.set_title(\"Size of clusters 1, 2 and 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 3.3c comment\n",
    "text_5 = \"\"\"Question 3.3c) One method of visualising the data in order to distinugish between road types \n",
    "would be a normalised parrallel co-ordinated graph, to determine any trends bewtween Arterial and Council Minor roads.\"\"\"\n",
    "print(text_5)\n",
    "\n",
    "# Question 3.3d\n",
    "# Reset index\n",
    "special_traffic_2_norm.index = special_traffic.index\n",
    "special_traffic_2_norm[\"StrType\"] = special_traffic[\"StrType\"]\n",
    "\n",
    "# Plot the Parallel coordinates\n",
    "fig = plt.figure(figsize=(25, 20))\n",
    "parallel_coordinates(special_traffic_2_norm.drop([\"clusters\"], axis = 1), \"StrType\", color = (\"red\", \"green\"))\n",
    "plt.xlabel('Attributes', fontsize=20)\n",
    "plt.ylabel('Relative size (units)', fontsize=20)\n",
    "plt.title(\"Parallel co-ordinate plot of the normalised special traffic dataframe\", fontsize=30)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Question answer\n",
    "text_6 = \"\"\"Question 3.3d) Here we can see a great seperation between the two road types, attibutes relating to speed\n",
    "are much lower on council minor roads as expected. Attibutes relating to number of cars shows that traffic through \n",
    "Arterial Roads is much greater with a lot of vehicle classes having zero traffic for some of the bigger vehicles,\n",
    "althought the reverse is true for bikes. This tells us our model effecitivly groups data based on \n",
    "street type.\"\"\"\n",
    "\n",
    "print(text_6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
